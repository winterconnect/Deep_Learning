{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "007_Keras_iris_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2bfl4-oAecQ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X_6DfF3Aj77"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "from keras.models import load_model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "odBF_b9OPGZC",
        "outputId": "c01564d3-09d6-4cd9-903b-ee742db2112b"
      },
      "source": [
        "# 버전 확인\n",
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "e7wGNEA7PKn1",
        "outputId": "bdc039ca-8388-40b8-b8c1-c2c7cb819d93"
      },
      "source": [
        "tf.keras.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7L-2KfJAm34"
      },
      "source": [
        "iris = sns.load_dataset('iris')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWQhV9GPAqiW",
        "outputId": "9d2f3ac6-e189-4227-b30c-ba10f93e8441"
      },
      "source": [
        "iris.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   species       150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uevwAzTyArlv",
        "outputId": "c4b25ef1-a9eb-4c33-b2aa-f14476f66176"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          3.5           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwnAtb27AuVx"
      },
      "source": [
        "## 1. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gb1Kb8pAwzW"
      },
      "source": [
        "### 1) iris.Species 빈도 분석\n",
        "- Species: setosa, virginica, versicolor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zq0kHFqPA126",
        "outputId": "7bdbcf44-5beb-47df-bf42-0b4d354bd064"
      },
      "source": [
        "iris.species.value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "virginica     50\n",
              "setosa        50\n",
              "versicolor    50\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qr5dRrEGA4a-"
      },
      "source": [
        "### 2) DataFrame to Array & Casting\n",
        "- 우리가 원하는 Tensor의 형태가 아니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROybj8gGAtbe",
        "outputId": "0d15768f-f70e-41a1-f94c-e4cb1ce8f992"
      },
      "source": [
        "iris_AR = iris.values\n",
        "# values를 하면 array로 빠진다\n",
        "\n",
        "iris_AR\n",
        "# 숫자만 들어있어야 하는데 문자가 들어있다"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2, 'setosa'],\n",
              "       [4.9, 3.0, 1.4, 0.2, 'setosa'],\n",
              "       [4.7, 3.2, 1.3, 0.2, 'setosa'],\n",
              "       [4.6, 3.1, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.6, 1.4, 0.2, 'setosa'],\n",
              "       [5.4, 3.9, 1.7, 0.4, 'setosa'],\n",
              "       [4.6, 3.4, 1.4, 0.3, 'setosa'],\n",
              "       [5.0, 3.4, 1.5, 0.2, 'setosa'],\n",
              "       [4.4, 2.9, 1.4, 0.2, 'setosa'],\n",
              "       [4.9, 3.1, 1.5, 0.1, 'setosa'],\n",
              "       [5.4, 3.7, 1.5, 0.2, 'setosa'],\n",
              "       [4.8, 3.4, 1.6, 0.2, 'setosa'],\n",
              "       [4.8, 3.0, 1.4, 0.1, 'setosa'],\n",
              "       [4.3, 3.0, 1.1, 0.1, 'setosa'],\n",
              "       [5.8, 4.0, 1.2, 0.2, 'setosa'],\n",
              "       [5.7, 4.4, 1.5, 0.4, 'setosa'],\n",
              "       [5.4, 3.9, 1.3, 0.4, 'setosa'],\n",
              "       [5.1, 3.5, 1.4, 0.3, 'setosa'],\n",
              "       [5.7, 3.8, 1.7, 0.3, 'setosa'],\n",
              "       [5.1, 3.8, 1.5, 0.3, 'setosa'],\n",
              "       [5.4, 3.4, 1.7, 0.2, 'setosa'],\n",
              "       [5.1, 3.7, 1.5, 0.4, 'setosa'],\n",
              "       [4.6, 3.6, 1.0, 0.2, 'setosa'],\n",
              "       [5.1, 3.3, 1.7, 0.5, 'setosa'],\n",
              "       [4.8, 3.4, 1.9, 0.2, 'setosa'],\n",
              "       [5.0, 3.0, 1.6, 0.2, 'setosa'],\n",
              "       [5.0, 3.4, 1.6, 0.4, 'setosa'],\n",
              "       [5.2, 3.5, 1.5, 0.2, 'setosa'],\n",
              "       [5.2, 3.4, 1.4, 0.2, 'setosa'],\n",
              "       [4.7, 3.2, 1.6, 0.2, 'setosa'],\n",
              "       [4.8, 3.1, 1.6, 0.2, 'setosa'],\n",
              "       [5.4, 3.4, 1.5, 0.4, 'setosa'],\n",
              "       [5.2, 4.1, 1.5, 0.1, 'setosa'],\n",
              "       [5.5, 4.2, 1.4, 0.2, 'setosa'],\n",
              "       [4.9, 3.1, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.2, 1.2, 0.2, 'setosa'],\n",
              "       [5.5, 3.5, 1.3, 0.2, 'setosa'],\n",
              "       [4.9, 3.6, 1.4, 0.1, 'setosa'],\n",
              "       [4.4, 3.0, 1.3, 0.2, 'setosa'],\n",
              "       [5.1, 3.4, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.5, 1.3, 0.3, 'setosa'],\n",
              "       [4.5, 2.3, 1.3, 0.3, 'setosa'],\n",
              "       [4.4, 3.2, 1.3, 0.2, 'setosa'],\n",
              "       [5.0, 3.5, 1.6, 0.6, 'setosa'],\n",
              "       [5.1, 3.8, 1.9, 0.4, 'setosa'],\n",
              "       [4.8, 3.0, 1.4, 0.3, 'setosa'],\n",
              "       [5.1, 3.8, 1.6, 0.2, 'setosa'],\n",
              "       [4.6, 3.2, 1.4, 0.2, 'setosa'],\n",
              "       [5.3, 3.7, 1.5, 0.2, 'setosa'],\n",
              "       [5.0, 3.3, 1.4, 0.2, 'setosa'],\n",
              "       [7.0, 3.2, 4.7, 1.4, 'versicolor'],\n",
              "       [6.4, 3.2, 4.5, 1.5, 'versicolor'],\n",
              "       [6.9, 3.1, 4.9, 1.5, 'versicolor'],\n",
              "       [5.5, 2.3, 4.0, 1.3, 'versicolor'],\n",
              "       [6.5, 2.8, 4.6, 1.5, 'versicolor'],\n",
              "       [5.7, 2.8, 4.5, 1.3, 'versicolor'],\n",
              "       [6.3, 3.3, 4.7, 1.6, 'versicolor'],\n",
              "       [4.9, 2.4, 3.3, 1.0, 'versicolor'],\n",
              "       [6.6, 2.9, 4.6, 1.3, 'versicolor'],\n",
              "       [5.2, 2.7, 3.9, 1.4, 'versicolor'],\n",
              "       [5.0, 2.0, 3.5, 1.0, 'versicolor'],\n",
              "       [5.9, 3.0, 4.2, 1.5, 'versicolor'],\n",
              "       [6.0, 2.2, 4.0, 1.0, 'versicolor'],\n",
              "       [6.1, 2.9, 4.7, 1.4, 'versicolor'],\n",
              "       [5.6, 2.9, 3.6, 1.3, 'versicolor'],\n",
              "       [6.7, 3.1, 4.4, 1.4, 'versicolor'],\n",
              "       [5.6, 3.0, 4.5, 1.5, 'versicolor'],\n",
              "       [5.8, 2.7, 4.1, 1.0, 'versicolor'],\n",
              "       [6.2, 2.2, 4.5, 1.5, 'versicolor'],\n",
              "       [5.6, 2.5, 3.9, 1.1, 'versicolor'],\n",
              "       [5.9, 3.2, 4.8, 1.8, 'versicolor'],\n",
              "       [6.1, 2.8, 4.0, 1.3, 'versicolor'],\n",
              "       [6.3, 2.5, 4.9, 1.5, 'versicolor'],\n",
              "       [6.1, 2.8, 4.7, 1.2, 'versicolor'],\n",
              "       [6.4, 2.9, 4.3, 1.3, 'versicolor'],\n",
              "       [6.6, 3.0, 4.4, 1.4, 'versicolor'],\n",
              "       [6.8, 2.8, 4.8, 1.4, 'versicolor'],\n",
              "       [6.7, 3.0, 5.0, 1.7, 'versicolor'],\n",
              "       [6.0, 2.9, 4.5, 1.5, 'versicolor'],\n",
              "       [5.7, 2.6, 3.5, 1.0, 'versicolor'],\n",
              "       [5.5, 2.4, 3.8, 1.1, 'versicolor'],\n",
              "       [5.5, 2.4, 3.7, 1.0, 'versicolor'],\n",
              "       [5.8, 2.7, 3.9, 1.2, 'versicolor'],\n",
              "       [6.0, 2.7, 5.1, 1.6, 'versicolor'],\n",
              "       [5.4, 3.0, 4.5, 1.5, 'versicolor'],\n",
              "       [6.0, 3.4, 4.5, 1.6, 'versicolor'],\n",
              "       [6.7, 3.1, 4.7, 1.5, 'versicolor'],\n",
              "       [6.3, 2.3, 4.4, 1.3, 'versicolor'],\n",
              "       [5.6, 3.0, 4.1, 1.3, 'versicolor'],\n",
              "       [5.5, 2.5, 4.0, 1.3, 'versicolor'],\n",
              "       [5.5, 2.6, 4.4, 1.2, 'versicolor'],\n",
              "       [6.1, 3.0, 4.6, 1.4, 'versicolor'],\n",
              "       [5.8, 2.6, 4.0, 1.2, 'versicolor'],\n",
              "       [5.0, 2.3, 3.3, 1.0, 'versicolor'],\n",
              "       [5.6, 2.7, 4.2, 1.3, 'versicolor'],\n",
              "       [5.7, 3.0, 4.2, 1.2, 'versicolor'],\n",
              "       [5.7, 2.9, 4.2, 1.3, 'versicolor'],\n",
              "       [6.2, 2.9, 4.3, 1.3, 'versicolor'],\n",
              "       [5.1, 2.5, 3.0, 1.1, 'versicolor'],\n",
              "       [5.7, 2.8, 4.1, 1.3, 'versicolor'],\n",
              "       [6.3, 3.3, 6.0, 2.5, 'virginica'],\n",
              "       [5.8, 2.7, 5.1, 1.9, 'virginica'],\n",
              "       [7.1, 3.0, 5.9, 2.1, 'virginica'],\n",
              "       [6.3, 2.9, 5.6, 1.8, 'virginica'],\n",
              "       [6.5, 3.0, 5.8, 2.2, 'virginica'],\n",
              "       [7.6, 3.0, 6.6, 2.1, 'virginica'],\n",
              "       [4.9, 2.5, 4.5, 1.7, 'virginica'],\n",
              "       [7.3, 2.9, 6.3, 1.8, 'virginica'],\n",
              "       [6.7, 2.5, 5.8, 1.8, 'virginica'],\n",
              "       [7.2, 3.6, 6.1, 2.5, 'virginica'],\n",
              "       [6.5, 3.2, 5.1, 2.0, 'virginica'],\n",
              "       [6.4, 2.7, 5.3, 1.9, 'virginica'],\n",
              "       [6.8, 3.0, 5.5, 2.1, 'virginica'],\n",
              "       [5.7, 2.5, 5.0, 2.0, 'virginica'],\n",
              "       [5.8, 2.8, 5.1, 2.4, 'virginica'],\n",
              "       [6.4, 3.2, 5.3, 2.3, 'virginica'],\n",
              "       [6.5, 3.0, 5.5, 1.8, 'virginica'],\n",
              "       [7.7, 3.8, 6.7, 2.2, 'virginica'],\n",
              "       [7.7, 2.6, 6.9, 2.3, 'virginica'],\n",
              "       [6.0, 2.2, 5.0, 1.5, 'virginica'],\n",
              "       [6.9, 3.2, 5.7, 2.3, 'virginica'],\n",
              "       [5.6, 2.8, 4.9, 2.0, 'virginica'],\n",
              "       [7.7, 2.8, 6.7, 2.0, 'virginica'],\n",
              "       [6.3, 2.7, 4.9, 1.8, 'virginica'],\n",
              "       [6.7, 3.3, 5.7, 2.1, 'virginica'],\n",
              "       [7.2, 3.2, 6.0, 1.8, 'virginica'],\n",
              "       [6.2, 2.8, 4.8, 1.8, 'virginica'],\n",
              "       [6.1, 3.0, 4.9, 1.8, 'virginica'],\n",
              "       [6.4, 2.8, 5.6, 2.1, 'virginica'],\n",
              "       [7.2, 3.0, 5.8, 1.6, 'virginica'],\n",
              "       [7.4, 2.8, 6.1, 1.9, 'virginica'],\n",
              "       [7.9, 3.8, 6.4, 2.0, 'virginica'],\n",
              "       [6.4, 2.8, 5.6, 2.2, 'virginica'],\n",
              "       [6.3, 2.8, 5.1, 1.5, 'virginica'],\n",
              "       [6.1, 2.6, 5.6, 1.4, 'virginica'],\n",
              "       [7.7, 3.0, 6.1, 2.3, 'virginica'],\n",
              "       [6.3, 3.4, 5.6, 2.4, 'virginica'],\n",
              "       [6.4, 3.1, 5.5, 1.8, 'virginica'],\n",
              "       [6.0, 3.0, 4.8, 1.8, 'virginica'],\n",
              "       [6.9, 3.1, 5.4, 2.1, 'virginica'],\n",
              "       [6.7, 3.1, 5.6, 2.4, 'virginica'],\n",
              "       [6.9, 3.1, 5.1, 2.3, 'virginica'],\n",
              "       [5.8, 2.7, 5.1, 1.9, 'virginica'],\n",
              "       [6.8, 3.2, 5.9, 2.3, 'virginica'],\n",
              "       [6.7, 3.3, 5.7, 2.5, 'virginica'],\n",
              "       [6.7, 3.0, 5.2, 2.3, 'virginica'],\n",
              "       [6.3, 2.5, 5.0, 1.9, 'virginica'],\n",
              "       [6.5, 3.0, 5.2, 2.0, 'virginica'],\n",
              "       [6.2, 3.4, 5.4, 2.3, 'virginica'],\n",
              "       [5.9, 3.0, 5.1, 1.8, 'virginica']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVimK4asBQv2"
      },
      "source": [
        "- object to float"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFhs83akBLfK",
        "outputId": "d71af523-fcaf-463f-c129-70faea93c80e"
      },
      "source": [
        "AR_X = iris_AR[: , 0:4].astype(float)\n",
        "AR_y = iris_AR[: , 4] \n",
        "\n",
        "AR_X.shape, AR_y.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((150, 4), (150,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U65p_uQhOEbY",
        "outputId": "aeda70a0-655b-45e3-ba85-fb59a01c1339"
      },
      "source": [
        "AR_y\n",
        "# 여전히 문자가 들어있다"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
              "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
              "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
              "       'virginica', 'virginica', 'virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QUydVTNBhoF"
      },
      "source": [
        "### 3) One Hot Encoding with sklearn & Keras\n",
        "\n",
        "- LabelEncoder()\n",
        "  - ['setosa' , 'virginica', 'virsicolor'] to [0, 1, 2]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEUA6wdkBguv",
        "outputId": "5067ae1f-6f0e-4d87-e2e9-2b376741820e"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "\n",
        "AR_yLBE = encoder.fit_transform(AR_y)\n",
        "\n",
        "AR_yLBE"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huhsZJfgB5AI"
      },
      "source": [
        "- One-Hot Encoding - to_categorical()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at0RykuVB3Uy",
        "outputId": "6ddbd24a-6b35-43de-a5bd-35df4be30a4a"
      },
      "source": [
        "# keras OHE는 문자를 안받으므로 LabelEncoder로 숫자로 변환\n",
        "# sklearn OHE도 array로 바꿔주는 두 단계를 거쳐야 함\n",
        "# to_categorical 함수 사용\n",
        "\n",
        "AR_yOHE = tf.keras.utils.to_categorical(AR_yLBE)\n",
        "\n",
        "AR_yOHE"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxkOvjAXCRuD"
      },
      "source": [
        "### 4) Train & Test Split with sklearn Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94YtdxX7CQoC",
        "outputId": "d5d0a6e2-bd58-4a87-ea46-7a4d86f84614"
      },
      "source": [
        "# 전처리 후 Train Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(AR_X, AR_yOHE,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 2045)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "# input size는 이미 정해짐"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((105, 4), (45, 4), (105, 3), (45, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxucPMWQCkuq"
      },
      "source": [
        "## 2. Keras Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYZT5gwBCnDN"
      },
      "source": [
        "### 1) Model Define\n",
        "\n",
        "- 모델 신경망 구조 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNVuJXfiCkPe"
      },
      "source": [
        "# Sequential로 모델을 만듦\n",
        "Model_iris = models.Sequential()\n",
        "\n",
        "# Dense: Fully-connected 의미\n",
        "# units: node 개수\n",
        "# 층은 얼마든지 쌓든지 줄이든지 할 수 있다\n",
        "\n",
        "# 첫번째 Layer에서 input size 지정(이미 정해져있음)\n",
        "Model_iris.add(layers.Dense(units = 16, activation = 'relu' , input_shape = (4,)))\n",
        "Model_iris.add(layers.Dense(8, activation = 'relu'))\n",
        "\n",
        "# 모델 숫자가 정해져있음(Output size가 정해져 있으므로)\n",
        "Model_iris.add(layers.Dense(3, activation = 'softmax'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V8rEfRqDFVf"
      },
      "source": [
        "- 모델 구조 확인\n",
        "  - Layers & Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-9TimilDEsM",
        "outputId": "3dd6df5e-cfe0-4361-9dbd-fb5da7418e66"
      },
      "source": [
        "Model_iris.summary()\n",
        "# b는 레이어가 아니라 노드마다 있는 것"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 16)                80        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 27        \n",
            "=================================================================\n",
            "Total params: 243\n",
            "Trainable params: 243\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTO3oRb_EdBQ"
      },
      "source": [
        "- 모델 레이어 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "IEtS9c_aDJ_Q",
        "outputId": "033d3da8-7bc7-4c50-c912-639871a4190c"
      },
      "source": [
        "utils.plot_model(Model_iris)\n",
        "# 그림으로 그려줌\n",
        "# 일반적으로 summary를 사용한다"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0kEk-YPEp2M"
      },
      "source": [
        "### 3) Model Compile\n",
        "- 모델 학습방법 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thxJZWnSEoEf"
      },
      "source": [
        "# 어떤 모델을 만들지에 따라 compile방식은 거의 정해져있다\n",
        "\n",
        "# compile: 학습 방법 결정\n",
        "# categorical_crossentropy: 다중분류\n",
        "# binary: 이진분류\n",
        "# mse: 예측\n",
        "\n",
        "Model_iris.compile(loss = 'categorical_crossentropy',\n",
        "                   optimizer = 'adam', # sgd, momentum, RMSProp\n",
        "                   metrics = ['accuracy']) # 이진분류일 경우 precision, recall\n",
        "                                           # 예측: mse, mae"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1wD7qw0E0Uu"
      },
      "source": [
        "### 4) Model Fit\n",
        "- 모델 학습 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ii-PIIgEza6",
        "outputId": "e8f52b5f-fd34-4028-bb0c-726e6ce3816f"
      },
      "source": [
        "History_iris = Model_iris.fit(X_train, y_train,\n",
        "                             epochs = 500,\n",
        "                             batch_size = 7, # 한번에 7개씩 처리 (sgd 방식)\n",
        "                                             # 105개 train data를 7개씩 끊어서 학습 (15번)\n",
        "                                             # 7개를 15번 보면, 1 epoch\n",
        "                             validation_data = (X_test, y_test))\n",
        "\n",
        "# 한번 Epoch가 15개로 끊어져있음\n",
        "# 실제 경사하강은 15 * 500 번 이루어진다"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 30ms/step - loss: 1.4792 - accuracy: 0.3803 - val_loss: 1.4586 - val_accuracy: 0.3111\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.4896 - accuracy: 0.3043 - val_loss: 1.3301 - val_accuracy: 0.3111\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 1.4179 - accuracy: 0.3491 - val_loss: 1.2198 - val_accuracy: 0.3111\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1319 - accuracy: 0.4049 - val_loss: 1.1528 - val_accuracy: 0.3111\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2047 - accuracy: 0.2703 - val_loss: 1.1096 - val_accuracy: 0.3111\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0545 - accuracy: 0.3864 - val_loss: 1.0852 - val_accuracy: 0.3111\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0299 - accuracy: 0.3897 - val_loss: 1.0651 - val_accuracy: 0.3111\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0404 - accuracy: 0.3250 - val_loss: 1.0485 - val_accuracy: 0.3333\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0396 - accuracy: 0.2907 - val_loss: 1.0339 - val_accuracy: 0.3333\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9505 - accuracy: 0.4311 - val_loss: 1.0195 - val_accuracy: 0.3333\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0035 - accuracy: 0.3237 - val_loss: 1.0053 - val_accuracy: 0.3333\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9618 - accuracy: 0.3646 - val_loss: 0.9914 - val_accuracy: 0.3333\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9435 - accuracy: 0.3777 - val_loss: 0.9773 - val_accuracy: 0.3333\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9427 - accuracy: 0.3564 - val_loss: 0.9627 - val_accuracy: 0.3333\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9078 - accuracy: 0.4044 - val_loss: 0.9495 - val_accuracy: 0.3333\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9581 - accuracy: 0.2931 - val_loss: 0.9339 - val_accuracy: 0.3333\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8749 - accuracy: 0.4057 - val_loss: 0.9182 - val_accuracy: 0.3333\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8378 - accuracy: 0.4370 - val_loss: 0.9031 - val_accuracy: 0.3333\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8394 - accuracy: 0.4099 - val_loss: 0.8879 - val_accuracy: 0.3333\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8454 - accuracy: 0.3809 - val_loss: 0.8723 - val_accuracy: 0.3333\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8527 - accuracy: 0.3595 - val_loss: 0.8575 - val_accuracy: 0.3556\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8511 - accuracy: 0.3347 - val_loss: 0.8425 - val_accuracy: 0.3556\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8194 - accuracy: 0.3933 - val_loss: 0.8281 - val_accuracy: 0.3556\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7819 - accuracy: 0.4658 - val_loss: 0.8146 - val_accuracy: 0.3778\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.5648 - val_loss: 0.7995 - val_accuracy: 0.4222\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8032 - accuracy: 0.6815 - val_loss: 0.7836 - val_accuracy: 0.6889\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7615 - accuracy: 0.7611 - val_loss: 0.7696 - val_accuracy: 0.7333\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7439 - accuracy: 0.7630 - val_loss: 0.7547 - val_accuracy: 0.8000\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7254 - accuracy: 0.7983 - val_loss: 0.7420 - val_accuracy: 0.7778\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7233 - accuracy: 0.8792 - val_loss: 0.7324 - val_accuracy: 0.8889\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.8649 - val_loss: 0.7213 - val_accuracy: 0.9111\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.8876 - val_loss: 0.7114 - val_accuracy: 0.9778\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6635 - accuracy: 0.8651 - val_loss: 0.7028 - val_accuracy: 0.8444\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6778 - accuracy: 0.8295 - val_loss: 0.6912 - val_accuracy: 0.9556\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6795 - accuracy: 0.8829 - val_loss: 0.6805 - val_accuracy: 0.9556\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.9006 - val_loss: 0.6727 - val_accuracy: 0.9778\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6283 - accuracy: 0.9613 - val_loss: 0.6633 - val_accuracy: 0.9556\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.8367 - val_loss: 0.6524 - val_accuracy: 0.9556\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.9764 - val_loss: 0.6435 - val_accuracy: 0.9556\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6378 - accuracy: 0.9264 - val_loss: 0.6350 - val_accuracy: 0.9778\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.9256 - val_loss: 0.6259 - val_accuracy: 0.9556\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.9567 - val_loss: 0.6163 - val_accuracy: 0.9778\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.9169 - val_loss: 0.6065 - val_accuracy: 0.9778\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5986 - accuracy: 0.9598 - val_loss: 0.5976 - val_accuracy: 0.9778\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.9524 - val_loss: 0.5888 - val_accuracy: 0.9778\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5784 - accuracy: 0.9363 - val_loss: 0.5790 - val_accuracy: 0.9778\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5519 - accuracy: 0.9298 - val_loss: 0.5698 - val_accuracy: 0.9778\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5473 - accuracy: 0.9480 - val_loss: 0.5612 - val_accuracy: 0.9778\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.9477 - val_loss: 0.5527 - val_accuracy: 0.9778\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.9512 - val_loss: 0.5432 - val_accuracy: 0.9778\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5370 - accuracy: 0.9378 - val_loss: 0.5337 - val_accuracy: 0.9778\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.9416 - val_loss: 0.5259 - val_accuracy: 0.9778\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.9601 - val_loss: 0.5168 - val_accuracy: 0.9778\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5114 - accuracy: 0.9362 - val_loss: 0.5087 - val_accuracy: 0.9778\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.9314 - val_loss: 0.4984 - val_accuracy: 0.9778\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.9371 - val_loss: 0.4902 - val_accuracy: 0.9778\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.9422 - val_loss: 0.4845 - val_accuracy: 0.9778\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.9672 - val_loss: 0.4755 - val_accuracy: 0.9778\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.9782 - val_loss: 0.4664 - val_accuracy: 0.9778\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.9686 - val_loss: 0.4571 - val_accuracy: 1.0000\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.9449 - val_loss: 0.4513 - val_accuracy: 0.9778\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.9111 - val_loss: 0.4399 - val_accuracy: 1.0000\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.9516 - val_loss: 0.4318 - val_accuracy: 0.9778\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.9407 - val_loss: 0.4233 - val_accuracy: 1.0000\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.9679 - val_loss: 0.4153 - val_accuracy: 1.0000\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.9698 - val_loss: 0.4079 - val_accuracy: 0.9778\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.9722 - val_loss: 0.3994 - val_accuracy: 1.0000\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.9908 - val_loss: 0.3917 - val_accuracy: 0.9778\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.9589 - val_loss: 0.3832 - val_accuracy: 1.0000\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3857 - accuracy: 0.9693 - val_loss: 0.3764 - val_accuracy: 1.0000\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.9500 - val_loss: 0.3705 - val_accuracy: 0.9778\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.9932 - val_loss: 0.3618 - val_accuracy: 0.9778\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.9956 - val_loss: 0.3538 - val_accuracy: 1.0000\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.9772 - val_loss: 0.3461 - val_accuracy: 1.0000\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3585 - accuracy: 0.9649 - val_loss: 0.3387 - val_accuracy: 1.0000\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.9620 - val_loss: 0.3324 - val_accuracy: 0.9778\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3631 - accuracy: 0.9382 - val_loss: 0.3238 - val_accuracy: 1.0000\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3172 - accuracy: 0.9829 - val_loss: 0.3170 - val_accuracy: 1.0000\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.9771 - val_loss: 0.3096 - val_accuracy: 1.0000\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.9931 - val_loss: 0.3028 - val_accuracy: 1.0000\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2950 - accuracy: 0.9833 - val_loss: 0.2963 - val_accuracy: 1.0000\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2864 - accuracy: 0.9777 - val_loss: 0.2915 - val_accuracy: 0.9778\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.9529 - val_loss: 0.2829 - val_accuracy: 1.0000\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.9707 - val_loss: 0.2767 - val_accuracy: 0.9778\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2904 - accuracy: 0.9859 - val_loss: 0.2701 - val_accuracy: 1.0000\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2683 - accuracy: 0.9858 - val_loss: 0.2641 - val_accuracy: 1.0000\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2705 - accuracy: 0.9859 - val_loss: 0.2576 - val_accuracy: 1.0000\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.9746 - val_loss: 0.2515 - val_accuracy: 1.0000\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.9683 - val_loss: 0.2481 - val_accuracy: 0.9778\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2582 - accuracy: 0.9861 - val_loss: 0.2397 - val_accuracy: 1.0000\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.9760 - val_loss: 0.2361 - val_accuracy: 0.9778\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2720 - accuracy: 0.9852 - val_loss: 0.2286 - val_accuracy: 1.0000\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.9811 - val_loss: 0.2232 - val_accuracy: 1.0000\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9852 - val_loss: 0.2185 - val_accuracy: 0.9778\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9907 - val_loss: 0.2126 - val_accuracy: 1.0000\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2085 - accuracy: 0.9922 - val_loss: 0.2073 - val_accuracy: 1.0000\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1995 - accuracy: 0.9866 - val_loss: 0.2025 - val_accuracy: 1.0000\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2103 - accuracy: 0.9799 - val_loss: 0.1977 - val_accuracy: 0.9778\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2248 - accuracy: 0.9785 - val_loss: 0.1929 - val_accuracy: 1.0000\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9600 - val_loss: 0.1885 - val_accuracy: 0.9778\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.9721 - val_loss: 0.1837 - val_accuracy: 1.0000\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9850 - val_loss: 0.1794 - val_accuracy: 1.0000\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2079 - accuracy: 0.9752 - val_loss: 0.1772 - val_accuracy: 0.9778\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9716 - val_loss: 0.1711 - val_accuracy: 1.0000\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1845 - accuracy: 0.9743 - val_loss: 0.1672 - val_accuracy: 1.0000\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.9633 - val_loss: 0.1640 - val_accuracy: 0.9778\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1896 - accuracy: 0.9872 - val_loss: 0.1599 - val_accuracy: 1.0000\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9554 - val_loss: 0.1574 - val_accuracy: 0.9778\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1877 - accuracy: 0.9596 - val_loss: 0.1527 - val_accuracy: 1.0000\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9736 - val_loss: 0.1535 - val_accuracy: 0.9778\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1756 - accuracy: 0.9843 - val_loss: 0.1458 - val_accuracy: 1.0000\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1890 - accuracy: 0.9532 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1518 - accuracy: 0.9847 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.2146 - accuracy: 0.9396 - val_loss: 0.1369 - val_accuracy: 0.9778\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1571 - accuracy: 0.9847 - val_loss: 0.1338 - val_accuracy: 0.9778\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.9764 - val_loss: 0.1326 - val_accuracy: 0.9778\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9689 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1478 - accuracy: 0.9718 - val_loss: 0.1277 - val_accuracy: 0.9778\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9828 - val_loss: 0.1233 - val_accuracy: 0.9778\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1589 - accuracy: 0.9764 - val_loss: 0.1224 - val_accuracy: 0.9778\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9867 - val_loss: 0.1190 - val_accuracy: 0.9778\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9761 - val_loss: 0.1188 - val_accuracy: 0.9778\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9794 - val_loss: 0.1141 - val_accuracy: 1.0000\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9646 - val_loss: 0.1141 - val_accuracy: 0.9778\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.9908 - val_loss: 0.1099 - val_accuracy: 1.0000\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1246 - accuracy: 0.9702 - val_loss: 0.1114 - val_accuracy: 0.9778\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9831 - val_loss: 0.1064 - val_accuracy: 1.0000\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.9619 - val_loss: 0.1114 - val_accuracy: 0.9778\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1490 - accuracy: 0.9693 - val_loss: 0.1026 - val_accuracy: 1.0000\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1327 - accuracy: 0.9594 - val_loss: 0.1018 - val_accuracy: 0.9778\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1220 - accuracy: 0.9857 - val_loss: 0.1014 - val_accuracy: 0.9778\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9898 - val_loss: 0.0977 - val_accuracy: 1.0000\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.9720 - val_loss: 0.0968 - val_accuracy: 0.9778\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9749 - val_loss: 0.0953 - val_accuracy: 0.9778\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.9741 - val_loss: 0.0951 - val_accuracy: 0.9778\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9854 - val_loss: 0.0927 - val_accuracy: 0.9778\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9821 - val_loss: 0.0952 - val_accuracy: 0.9778\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9942 - val_loss: 0.0903 - val_accuracy: 0.9778\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.9852 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9708 - val_loss: 0.0867 - val_accuracy: 0.9778\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9899 - val_loss: 0.0860 - val_accuracy: 0.9778\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1168 - accuracy: 0.9782 - val_loss: 0.0853 - val_accuracy: 0.9778\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1257 - accuracy: 0.9673 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9861 - val_loss: 0.0856 - val_accuracy: 0.9778\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9778 - val_loss: 0.0815 - val_accuracy: 0.9778\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.9777 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1162 - accuracy: 0.9810 - val_loss: 0.0808 - val_accuracy: 0.9778\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1121 - accuracy: 0.9869 - val_loss: 0.0811 - val_accuracy: 0.9778\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.9799 - val_loss: 0.0768 - val_accuracy: 1.0000\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9728 - val_loss: 0.0767 - val_accuracy: 0.9778\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9804 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.9667 - val_loss: 0.0761 - val_accuracy: 0.9778\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9861 - val_loss: 0.0740 - val_accuracy: 0.9778\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9754 - val_loss: 0.0725 - val_accuracy: 0.9778\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1277 - accuracy: 0.9559 - val_loss: 0.0721 - val_accuracy: 0.9778\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1223 - accuracy: 0.9704 - val_loss: 0.0730 - val_accuracy: 0.9778\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9768 - val_loss: 0.0710 - val_accuracy: 0.9778\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9788 - val_loss: 0.0693 - val_accuracy: 0.9778\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9843 - val_loss: 0.0707 - val_accuracy: 0.9778\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9891 - val_loss: 0.0693 - val_accuracy: 0.9778\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9922 - val_loss: 0.0673 - val_accuracy: 0.9778\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9818 - val_loss: 0.0720 - val_accuracy: 0.9778\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1097 - accuracy: 0.9715 - val_loss: 0.0661 - val_accuracy: 0.9778\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1150 - accuracy: 0.9600 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0924 - accuracy: 0.9872 - val_loss: 0.0673 - val_accuracy: 0.9778\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9812 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9880 - val_loss: 0.0650 - val_accuracy: 0.9778\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1021 - accuracy: 0.9713 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9813 - val_loss: 0.0637 - val_accuracy: 0.9778\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 0.9689 - val_loss: 0.0621 - val_accuracy: 0.9778\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9619 - val_loss: 0.0629 - val_accuracy: 0.9778\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.9679 - val_loss: 0.0602 - val_accuracy: 0.9778\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9782 - val_loss: 0.0614 - val_accuracy: 0.9778\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0857 - accuracy: 0.9976 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9768 - val_loss: 0.0662 - val_accuracy: 0.9778\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0995 - accuracy: 0.9807 - val_loss: 0.0599 - val_accuracy: 0.9778\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9850 - val_loss: 0.0615 - val_accuracy: 0.9778\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9749 - val_loss: 0.0663 - val_accuracy: 0.9778\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0781 - accuracy: 0.9908 - val_loss: 0.0564 - val_accuracy: 1.0000\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0756 - accuracy: 0.9898 - val_loss: 0.0606 - val_accuracy: 0.9778\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1035 - accuracy: 0.9867 - val_loss: 0.0583 - val_accuracy: 0.9778\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9698 - val_loss: 0.0560 - val_accuracy: 0.9778\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9883 - val_loss: 0.0561 - val_accuracy: 0.9778\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9938 - val_loss: 0.0556 - val_accuracy: 0.9778\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9785 - val_loss: 0.0582 - val_accuracy: 0.9778\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9649 - val_loss: 0.0541 - val_accuracy: 0.9778\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9875 - val_loss: 0.0547 - val_accuracy: 0.9778\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1182 - accuracy: 0.9657 - val_loss: 0.0570 - val_accuracy: 0.9778\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1247 - accuracy: 0.9681 - val_loss: 0.0522 - val_accuracy: 1.0000\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0792 - accuracy: 0.9881 - val_loss: 0.0633 - val_accuracy: 0.9778\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9800 - val_loss: 0.0533 - val_accuracy: 0.9778\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9753 - val_loss: 0.0512 - val_accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1002 - accuracy: 0.9715 - val_loss: 0.0607 - val_accuracy: 0.9778\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0826 - accuracy: 0.9645 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0927 - accuracy: 0.9660 - val_loss: 0.0529 - val_accuracy: 0.9778\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9666 - val_loss: 0.0527 - val_accuracy: 0.9778\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.9798 - val_loss: 0.0499 - val_accuracy: 0.9778\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9782 - val_loss: 0.0575 - val_accuracy: 0.9778\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 0.9476 - val_loss: 0.0495 - val_accuracy: 0.9778\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 0.9842 - val_loss: 0.0542 - val_accuracy: 0.9778\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9861 - val_loss: 0.0505 - val_accuracy: 0.9778\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1020 - accuracy: 0.9745 - val_loss: 0.0522 - val_accuracy: 0.9778\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9861 - val_loss: 0.0513 - val_accuracy: 0.9778\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9857 - val_loss: 0.0520 - val_accuracy: 0.9778\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9927 - val_loss: 0.0481 - val_accuracy: 0.9778\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9736 - val_loss: 0.0552 - val_accuracy: 0.9778\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9734 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1302 - accuracy: 0.9599 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0647 - accuracy: 0.9957 - val_loss: 0.0486 - val_accuracy: 0.9778\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9890 - val_loss: 0.0479 - val_accuracy: 0.9778\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9950 - val_loss: 0.0524 - val_accuracy: 0.9778\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9813 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9673 - val_loss: 0.0454 - val_accuracy: 0.9778\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9791 - val_loss: 0.0488 - val_accuracy: 0.9778\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9868 - val_loss: 0.0455 - val_accuracy: 0.9778\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9910 - val_loss: 0.0509 - val_accuracy: 0.9778\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9880 - val_loss: 0.0509 - val_accuracy: 0.9778\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9802 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9830 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9498 - val_loss: 0.0476 - val_accuracy: 0.9778\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0720 - accuracy: 0.9897 - val_loss: 0.0465 - val_accuracy: 0.9778\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9746 - val_loss: 0.0441 - val_accuracy: 0.9778\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9832 - val_loss: 0.0465 - val_accuracy: 0.9778\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9922 - val_loss: 0.0436 - val_accuracy: 0.9778\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9679 - val_loss: 0.0490 - val_accuracy: 0.9778\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0997 - accuracy: 0.9775 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1031 - accuracy: 0.9775 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9723 - val_loss: 0.0430 - val_accuracy: 0.9778\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9813 - val_loss: 0.0470 - val_accuracy: 0.9778\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9889 - val_loss: 0.0462 - val_accuracy: 0.9778\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9812 - val_loss: 0.0443 - val_accuracy: 0.9778\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9859 - val_loss: 0.0459 - val_accuracy: 0.9778\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9782 - val_loss: 0.0481 - val_accuracy: 0.9778\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9673 - val_loss: 0.0416 - val_accuracy: 0.9778\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9876 - val_loss: 0.0455 - val_accuracy: 0.9778\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9834 - val_loss: 0.0457 - val_accuracy: 0.9778\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0638 - accuracy: 0.9859 - val_loss: 0.0414 - val_accuracy: 0.9778\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0543 - accuracy: 0.9889 - val_loss: 0.0503 - val_accuracy: 0.9778\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0825 - accuracy: 0.9763 - val_loss: 0.0426 - val_accuracy: 0.9778\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9976 - val_loss: 0.0400 - val_accuracy: 0.9778\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9915 - val_loss: 0.0518 - val_accuracy: 0.9778\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9596 - val_loss: 0.0420 - val_accuracy: 0.9778\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0774 - accuracy: 0.9689 - val_loss: 0.0465 - val_accuracy: 0.9778\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9829 - val_loss: 0.0397 - val_accuracy: 0.9778\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9941 - val_loss: 0.0416 - val_accuracy: 0.9778\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0942 - accuracy: 0.9614 - val_loss: 0.0451 - val_accuracy: 0.9778\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0768 - accuracy: 0.9748 - val_loss: 0.0411 - val_accuracy: 0.9778\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9729 - val_loss: 0.0398 - val_accuracy: 0.9778\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9693 - val_loss: 0.0438 - val_accuracy: 0.9778\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9812 - val_loss: 0.0405 - val_accuracy: 0.9778\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9915 - val_loss: 0.0432 - val_accuracy: 0.9778\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1150 - accuracy: 0.9582 - val_loss: 0.0428 - val_accuracy: 0.9778\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9748 - val_loss: 0.0405 - val_accuracy: 0.9778\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9857 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0625 - accuracy: 0.9867 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1051 - accuracy: 0.9614 - val_loss: 0.0425 - val_accuracy: 0.9778\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9878 - val_loss: 0.0367 - val_accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9963 - val_loss: 0.0469 - val_accuracy: 0.9778\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9831 - val_loss: 0.0383 - val_accuracy: 0.9778\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9813 - val_loss: 0.0423 - val_accuracy: 0.9778\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9857 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9693 - val_loss: 0.0423 - val_accuracy: 0.9778\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.9679 - val_loss: 0.0381 - val_accuracy: 0.9778\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9687 - val_loss: 0.0425 - val_accuracy: 0.9778\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0866 - accuracy: 0.9754 - val_loss: 0.0382 - val_accuracy: 0.9778\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0604 - accuracy: 0.9859 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9648 - val_loss: 0.0387 - val_accuracy: 0.9778\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0513 - accuracy: 0.9910 - val_loss: 0.0362 - val_accuracy: 0.9778\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9836 - val_loss: 0.0444 - val_accuracy: 0.9778\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9826 - val_loss: 0.0380 - val_accuracy: 0.9778\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9905 - val_loss: 0.0493 - val_accuracy: 0.9778\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9869 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0522 - accuracy: 0.9884 - val_loss: 0.0474 - val_accuracy: 0.9778\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9760 - val_loss: 0.0357 - val_accuracy: 0.9778\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9559 - val_loss: 0.0408 - val_accuracy: 0.9778\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0896 - accuracy: 0.9559 - val_loss: 0.0403 - val_accuracy: 0.9778\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9879 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9911 - val_loss: 0.0405 - val_accuracy: 0.9778\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9881 - val_loss: 0.0425 - val_accuracy: 0.9778\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9970 - val_loss: 0.0367 - val_accuracy: 0.9778\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9734 - val_loss: 0.0372 - val_accuracy: 0.9778\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0861 - accuracy: 0.9582 - val_loss: 0.0372 - val_accuracy: 0.9778\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9627 - val_loss: 0.0387 - val_accuracy: 0.9778\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9900 - val_loss: 0.0371 - val_accuracy: 0.9778\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9929 - val_loss: 0.0465 - val_accuracy: 0.9778\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9559 - val_loss: 0.0439 - val_accuracy: 0.9778\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9957 - val_loss: 0.0375 - val_accuracy: 0.9778\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9737 - val_loss: 0.0406 - val_accuracy: 0.9778\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9876 - val_loss: 0.0372 - val_accuracy: 0.9778\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0533 - accuracy: 0.9904 - val_loss: 0.0382 - val_accuracy: 0.9778\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9934 - val_loss: 0.0423 - val_accuracy: 0.9778\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0725 - accuracy: 0.9784 - val_loss: 0.0428 - val_accuracy: 0.9778\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9698 - val_loss: 0.0376 - val_accuracy: 0.9778\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0549 - accuracy: 0.9803 - val_loss: 0.0360 - val_accuracy: 0.9778\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9842 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0539 - accuracy: 0.9908 - val_loss: 0.0380 - val_accuracy: 0.9778\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9842 - val_loss: 0.0386 - val_accuracy: 0.9778\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9800 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0755 - accuracy: 0.9821 - val_loss: 0.0421 - val_accuracy: 0.9778\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9890 - val_loss: 0.0337 - val_accuracy: 0.9778\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9775 - val_loss: 0.0357 - val_accuracy: 0.9778\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9881 - val_loss: 0.0443 - val_accuracy: 0.9778\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0850 - accuracy: 0.9733 - val_loss: 0.0344 - val_accuracy: 0.9778\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9833 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9726 - val_loss: 0.0467 - val_accuracy: 0.9778\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9904 - val_loss: 0.0360 - val_accuracy: 0.9778\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9802 - val_loss: 0.0384 - val_accuracy: 0.9778\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9831 - val_loss: 0.0390 - val_accuracy: 0.9778\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0888 - accuracy: 0.9671 - val_loss: 0.0364 - val_accuracy: 0.9778\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9898 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0575 - accuracy: 0.9866 - val_loss: 0.0448 - val_accuracy: 0.9778\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9799 - val_loss: 0.0331 - val_accuracy: 0.9778\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9840 - val_loss: 0.0387 - val_accuracy: 0.9778\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9970 - val_loss: 0.0356 - val_accuracy: 0.9778\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 0.9908 - val_loss: 0.0398 - val_accuracy: 0.9778\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9791 - val_loss: 0.0389 - val_accuracy: 0.9778\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9740 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9852 - val_loss: 0.0426 - val_accuracy: 0.9778\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0940 - accuracy: 0.9748 - val_loss: 0.0339 - val_accuracy: 0.9778\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9861 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.0463 - val_accuracy: 0.9778\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9559 - val_loss: 0.0352 - val_accuracy: 0.9778\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 0.0345 - val_accuracy: 0.9778\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9693 - val_loss: 0.0403 - val_accuracy: 0.9778\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9842 - val_loss: 0.0385 - val_accuracy: 0.9778\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9821 - val_loss: 0.0386 - val_accuracy: 0.9778\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9922 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9891 - val_loss: 0.0356 - val_accuracy: 0.9778\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9820 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9733 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9900 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.9940 - val_loss: 0.0352 - val_accuracy: 0.9778\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9644 - val_loss: 0.0366 - val_accuracy: 0.9778\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9836 - val_loss: 0.0338 - val_accuracy: 0.9778\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0490 - accuracy: 0.9927 - val_loss: 0.0385 - val_accuracy: 0.9778\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9480 - val_loss: 0.0388 - val_accuracy: 0.9778\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0491 - accuracy: 0.9891 - val_loss: 0.0354 - val_accuracy: 0.9778\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9693 - val_loss: 0.0387 - val_accuracy: 0.9778\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0698 - accuracy: 0.9843 - val_loss: 0.0310 - val_accuracy: 0.9778\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9941 - val_loss: 0.0381 - val_accuracy: 0.9778\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9813 - val_loss: 0.0351 - val_accuracy: 0.9778\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9938 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0592 - accuracy: 0.9775 - val_loss: 0.0417 - val_accuracy: 0.9778\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9988 - val_loss: 0.0306 - val_accuracy: 0.9778\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9730 - val_loss: 0.0402 - val_accuracy: 0.9778\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9842 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9698 - val_loss: 0.0376 - val_accuracy: 0.9778\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9850 - val_loss: 0.0309 - val_accuracy: 0.9778\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9859 - val_loss: 0.0435 - val_accuracy: 0.9778\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9857 - val_loss: 0.0384 - val_accuracy: 0.9778\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9947 - val_loss: 0.0311 - val_accuracy: 0.9778\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9919 - val_loss: 0.0424 - val_accuracy: 0.9778\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0625 - accuracy: 0.9884 - val_loss: 0.0353 - val_accuracy: 0.9778\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9826 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9950 - val_loss: 0.0369 - val_accuracy: 0.9778\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9934 - val_loss: 0.0353 - val_accuracy: 0.9778\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9963 - val_loss: 0.0351 - val_accuracy: 0.9778\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9902 - val_loss: 0.0411 - val_accuracy: 0.9778\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.0334 - val_accuracy: 0.9778\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0721 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9850 - val_loss: 0.0359 - val_accuracy: 0.9778\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9890 - val_loss: 0.0348 - val_accuracy: 0.9778\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9781 - val_loss: 0.0389 - val_accuracy: 0.9778\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9791 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0616 - accuracy: 0.9852 - val_loss: 0.0396 - val_accuracy: 0.9778\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9802 - val_loss: 0.0424 - val_accuracy: 0.9778\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9719 - val_loss: 0.0313 - val_accuracy: 0.9778\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9785 - val_loss: 0.0391 - val_accuracy: 0.9778\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9876 - val_loss: 0.0368 - val_accuracy: 0.9778\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9782 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9880 - val_loss: 0.0422 - val_accuracy: 0.9778\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9932 - val_loss: 0.0351 - val_accuracy: 0.9778\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9663 - val_loss: 0.0344 - val_accuracy: 0.9778\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9772 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9870 - val_loss: 0.0335 - val_accuracy: 0.9778\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0457 - accuracy: 0.9890 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9910 - val_loss: 0.0363 - val_accuracy: 0.9778\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9917 - val_loss: 0.0367 - val_accuracy: 0.9778\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9778 - val_loss: 0.0351 - val_accuracy: 0.9778\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9787 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0415 - accuracy: 0.9891 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0553 - accuracy: 0.9938 - val_loss: 0.0328 - val_accuracy: 0.9778\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0650 - accuracy: 0.9866 - val_loss: 0.0477 - val_accuracy: 0.9778\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0767 - accuracy: 0.9787 - val_loss: 0.0299 - val_accuracy: 0.9778\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9778 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9791 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9905 - val_loss: 0.0320 - val_accuracy: 0.9778\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9686 - val_loss: 0.0373 - val_accuracy: 0.9778\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9836 - val_loss: 0.0349 - val_accuracy: 0.9778\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9821 - val_loss: 0.0361 - val_accuracy: 0.9778\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9850 - val_loss: 0.0304 - val_accuracy: 0.9778\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9536 - val_loss: 0.0367 - val_accuracy: 0.9778\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0632 - accuracy: 0.9689 - val_loss: 0.0302 - val_accuracy: 0.9778\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9890 - val_loss: 0.0338 - val_accuracy: 0.9778\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0519 - accuracy: 0.9934 - val_loss: 0.0352 - val_accuracy: 0.9778\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9671 - val_loss: 0.0402 - val_accuracy: 0.9778\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0779 - accuracy: 0.9737 - val_loss: 0.0291 - val_accuracy: 0.9778\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 0.0316 - val_accuracy: 0.9778\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9938 - val_loss: 0.0353 - val_accuracy: 0.9778\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9836 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9702 - val_loss: 0.0376 - val_accuracy: 0.9778\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9778 - val_loss: 0.0331 - val_accuracy: 0.9778\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9947 - val_loss: 0.0322 - val_accuracy: 0.9778\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9540 - val_loss: 0.0371 - val_accuracy: 0.9778\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0693 - accuracy: 0.9638 - val_loss: 0.0283 - val_accuracy: 0.9778\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9976 - val_loss: 0.0281 - val_accuracy: 0.9778\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9886 - val_loss: 0.0450 - val_accuracy: 0.9778\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9902 - val_loss: 0.0341 - val_accuracy: 0.9778\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9821 - val_loss: 0.0307 - val_accuracy: 0.9778\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9942 - val_loss: 0.0351 - val_accuracy: 0.9778\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0860 - accuracy: 0.9787 - val_loss: 0.0391 - val_accuracy: 0.9778\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0509 - accuracy: 0.9905 - val_loss: 0.0397 - val_accuracy: 0.9778\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9831 - val_loss: 0.0326 - val_accuracy: 0.9778\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0953 - accuracy: 0.9647 - val_loss: 0.0299 - val_accuracy: 0.9778\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0992 - accuracy: 0.9671 - val_loss: 0.0412 - val_accuracy: 0.9778\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9904 - val_loss: 0.0329 - val_accuracy: 0.9778\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9828 - val_loss: 0.0364 - val_accuracy: 0.9778\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0736 - accuracy: 0.9775 - val_loss: 0.0282 - val_accuracy: 0.9778\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9859 - val_loss: 0.0360 - val_accuracy: 0.9778\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9642 - val_loss: 0.0373 - val_accuracy: 0.9778\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9599 - val_loss: 0.0293 - val_accuracy: 0.9778\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9866 - val_loss: 0.0370 - val_accuracy: 0.9778\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9761 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9425 - val_loss: 0.0276 - val_accuracy: 0.9778\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9846 - val_loss: 0.0349 - val_accuracy: 0.9778\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9956 - val_loss: 0.0332 - val_accuracy: 0.9778\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0589 - accuracy: 0.9868 - val_loss: 0.0441 - val_accuracy: 0.9778\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9947 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9586 - val_loss: 0.0447 - val_accuracy: 0.9778\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 0.0308 - val_accuracy: 0.9778\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9869 - val_loss: 0.0421 - val_accuracy: 0.9778\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9911 - val_loss: 0.0319 - val_accuracy: 0.9778\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9897 - val_loss: 0.0366 - val_accuracy: 0.9778\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0593 - accuracy: 0.9749 - val_loss: 0.0445 - val_accuracy: 0.9778\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9815 - val_loss: 0.0264 - val_accuracy: 0.9778\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9932 - val_loss: 0.0401 - val_accuracy: 0.9778\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9799 - val_loss: 0.0388 - val_accuracy: 0.9778\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 0.9851 - val_loss: 0.0293 - val_accuracy: 0.9778\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9870 - val_loss: 0.0379 - val_accuracy: 0.9778\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9902 - val_loss: 0.0368 - val_accuracy: 0.9778\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9880 - val_loss: 0.0336 - val_accuracy: 0.9778\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9762 - val_loss: 0.0361 - val_accuracy: 0.9778\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9771 - val_loss: 0.0374 - val_accuracy: 0.9778\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9888 - val_loss: 0.0285 - val_accuracy: 0.9778\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0925 - accuracy: 0.9510 - val_loss: 0.0436 - val_accuracy: 0.9778\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0477 - accuracy: 0.9859 - val_loss: 0.0349 - val_accuracy: 0.9778\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0811 - accuracy: 0.9787 - val_loss: 0.0361 - val_accuracy: 0.9778\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0869 - accuracy: 0.9614 - val_loss: 0.0294 - val_accuracy: 0.9778\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9649 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9727 - val_loss: 0.0409 - val_accuracy: 0.9778\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9929 - val_loss: 0.0262 - val_accuracy: 0.9778\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9869 - val_loss: 0.0404 - val_accuracy: 0.9778\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9908 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9927 - val_loss: 0.0330 - val_accuracy: 0.9778\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9821 - val_loss: 0.0368 - val_accuracy: 0.9778\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9889 - val_loss: 0.0316 - val_accuracy: 0.9778\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9867 - val_loss: 0.0408 - val_accuracy: 0.9778\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.0299 - val_accuracy: 0.9778\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.9813 - val_loss: 0.0320 - val_accuracy: 0.9778\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9826 - val_loss: 0.0378 - val_accuracy: 0.9778\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0563 - accuracy: 0.9883 - val_loss: 0.0311 - val_accuracy: 0.9778\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9900 - val_loss: 0.0382 - val_accuracy: 0.9778\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9947 - val_loss: 0.0322 - val_accuracy: 0.9778\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9925 - val_loss: 0.0389 - val_accuracy: 0.9778\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0514 - accuracy: 0.9888 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9582 - val_loss: 0.0375 - val_accuracy: 0.9778\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0659 - accuracy: 0.9827 - val_loss: 0.0297 - val_accuracy: 0.9778\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9861 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0879 - accuracy: 0.9516 - val_loss: 0.0371 - val_accuracy: 0.9778\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9689 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9910 - val_loss: 0.0377 - val_accuracy: 0.9778\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9861 - val_loss: 0.0378 - val_accuracy: 0.9778\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0706 - accuracy: 0.9917 - val_loss: 0.0375 - val_accuracy: 0.9778\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9884 - val_loss: 0.0320 - val_accuracy: 0.9778\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0909 - accuracy: 0.9657 - val_loss: 0.0342 - val_accuracy: 0.9778\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9802 - val_loss: 0.0296 - val_accuracy: 0.9778\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.0357 - val_accuracy: 0.9778\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9733 - val_loss: 0.0353 - val_accuracy: 0.9778\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9917 - val_loss: 0.0331 - val_accuracy: 0.9778\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9857 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1028 - accuracy: 0.9599 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9663 - val_loss: 0.0342 - val_accuracy: 0.9778\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9976 - val_loss: 0.0278 - val_accuracy: 0.9778\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0697 - accuracy: 0.9590 - val_loss: 0.0408 - val_accuracy: 0.9778\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9906 - val_loss: 0.0276 - val_accuracy: 0.9778\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0481 - accuracy: 0.9929 - val_loss: 0.0410 - val_accuracy: 0.9778\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0648 - accuracy: 0.9715 - val_loss: 0.0436 - val_accuracy: 0.9778\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9950 - val_loss: 0.0310 - val_accuracy: 0.9778\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9770 - val_loss: 0.0400 - val_accuracy: 0.9778\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9883 - val_loss: 0.0258 - val_accuracy: 0.9778\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9949 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9633 - val_loss: 0.0393 - val_accuracy: 0.9778\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9698 - val_loss: 0.0250 - val_accuracy: 0.9778\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.9876 - val_loss: 0.0305 - val_accuracy: 0.9778\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0339 - accuracy: 0.9927 - val_loss: 0.0402 - val_accuracy: 0.9778\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9942 - val_loss: 0.0373 - val_accuracy: 0.9778\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0434 - accuracy: 0.9908 - val_loss: 0.0283 - val_accuracy: 0.9778\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.0610 - accuracy: 0.9791 - val_loss: 0.0393 - val_accuracy: 0.9778\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0411 - accuracy: 0.9938 - val_loss: 0.0307 - val_accuracy: 0.9778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jsFXMehF2Gh",
        "outputId": "2c2a4179-6a35-4d73-b8c7-8ed572876fb4"
      },
      "source": [
        "History_iris.history.keys()\n",
        "\n",
        "# loss, accuracy: train data\n",
        "# val_loss, val_accuracy: test data"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NNI1K-9FMp8"
      },
      "source": [
        "### 5) 학습결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "I7I7zrVhFP0H",
        "outputId": "1bfb9cfb-ca09-4c9b-e76b-b4823d1531d9"
      },
      "source": [
        "plt.figure(figsize = (9, 6))\n",
        "plt.ylim(0, 1.2)\n",
        "plt.plot(History_iris.history['loss'])\n",
        "plt.plot(History_iris.history['accuracy'])\n",
        "plt.plot(History_iris.history['val_loss'])\n",
        "plt.plot(History_iris.history['val_accuracy'])\n",
        "\n",
        "plt.legend(History_iris.history.keys())\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# accuracy는 1에 가까워지고 있고, loss는 0에 가까워지고 있음\n",
        "# 300번 정도만 해도 성능이 비슷하게 나옴을 볼 수 있다"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K34TFOMTGVcI"
      },
      "source": [
        "### 6) Model Evaluate\n",
        "- Loss & Accuracy\n",
        "- 여기서 마음에 안들면 앞 단계로 다시 돌아가야 한다\n",
        "(Hyperparameter tuning)\n",
        "  - 하나씩 바꿔가며 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HyeWvdSFH83",
        "outputId": "ef2b4011-5cbb-438e-c8ba-dc5cb43dd26d"
      },
      "source": [
        "loss, accuracy = Model_iris.evaluate(X_test, y_test)\n",
        "\n",
        "print('Loss = {:.2f}' .format(loss))\n",
        "print('Accuracy = {:.2f}' .format(accuracy))\n",
        "\n",
        "# 0.98이 나옴 (좋은 것인가 나쁜것인가는 판단해야 함)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9778\n",
            "Loss = 0.03\n",
            "Accuracy = 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTGVE71SGmCn"
      },
      "source": [
        "### 7) Model Predict\n",
        "- Probability\n",
        "- 함수: predict(예측), predict_classes(분류)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o1azaaPGjtm",
        "outputId": "8092b3dc-338c-4d0f-cad8-d874674651f2"
      },
      "source": [
        "np.set_printoptions(suppress = True, precision = 5)\n",
        "Model_iris.predict(X_test) # 확률값(probability)으로 나옴\n",
        "\n",
        "# softmax - 합이 1이 됨"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99829, 0.00047, 0.00124],\n",
              "       [0.99262, 0.00387, 0.00351],\n",
              "       [0.01222, 0.98306, 0.00472],\n",
              "       [0.     , 0.00003, 0.99997],\n",
              "       [0.99948, 0.00007, 0.00046],\n",
              "       [0.00036, 0.99893, 0.0007 ],\n",
              "       [0.     , 0.00591, 0.99408],\n",
              "       [0.99961, 0.00004, 0.00035],\n",
              "       [0.00001, 0.00046, 0.99953],\n",
              "       [0.99775, 0.00073, 0.00152],\n",
              "       [0.00047, 0.88453, 0.115  ],\n",
              "       [0.     , 0.00229, 0.99771],\n",
              "       [0.00001, 0.99676, 0.00322],\n",
              "       [0.99986, 0.00001, 0.00014],\n",
              "       [0.99947, 0.00008, 0.00046],\n",
              "       [0.0001 , 0.99595, 0.00395],\n",
              "       [0.00006, 0.98202, 0.01792],\n",
              "       [0.99869, 0.00028, 0.00104],\n",
              "       [0.00002, 0.9994 , 0.00058],\n",
              "       [0.99957, 0.00005, 0.00038],\n",
              "       [0.99813, 0.00053, 0.00134],\n",
              "       [0.99821, 0.00049, 0.0013 ],\n",
              "       [0.     , 0.00076, 0.99924],\n",
              "       [0.99886, 0.00024, 0.0009 ],\n",
              "       [0.     , 0.03725, 0.96275],\n",
              "       [0.00005, 0.01327, 0.98668],\n",
              "       [0.9993 , 0.00011, 0.00059],\n",
              "       [0.00003, 0.99601, 0.00396],\n",
              "       [0.00001, 0.99598, 0.00401],\n",
              "       [0.00004, 0.03786, 0.96211],\n",
              "       [0.9996 , 0.00004, 0.00036],\n",
              "       [0.00005, 0.99764, 0.00231],\n",
              "       [0.99951, 0.00007, 0.00042],\n",
              "       [0.00004, 0.65126, 0.3487 ],\n",
              "       [0.00007, 0.9939 , 0.00603],\n",
              "       [0.00015, 0.99928, 0.00057],\n",
              "       [0.     , 0.00006, 0.99994],\n",
              "       [0.00014, 0.99913, 0.00073],\n",
              "       [0.99861, 0.00035, 0.00105],\n",
              "       [0.00028, 0.99682, 0.00291],\n",
              "       [0.     , 0.00007, 0.99993],\n",
              "       [0.99847, 0.00041, 0.00112],\n",
              "       [0.00001, 0.00208, 0.99791],\n",
              "       [0.     , 0.0004 , 0.9996 ],\n",
              "       [0.00001, 0.01399, 0.98599]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr9vPPDqHFZ-"
      },
      "source": [
        "- Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iikfQ6FwHDdD",
        "outputId": "6730cbd7-f0df-4501-862c-91c998a41162"
      },
      "source": [
        "y_hat = Model_iris.predict_classes(X_test)\n",
        "y_hat"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNysJWx2HKzO"
      },
      "source": [
        "- Probability to Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfZ0rU1_VuUi",
        "outputId": "00b34982-5ee5-4eff-8b9f-05bcf8b0d0a4"
      },
      "source": [
        "Model_iris.predict(X_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99829, 0.00047, 0.00124],\n",
              "       [0.99262, 0.00387, 0.00351],\n",
              "       [0.01222, 0.98306, 0.00472],\n",
              "       [0.     , 0.00003, 0.99997],\n",
              "       [0.99948, 0.00007, 0.00046],\n",
              "       [0.00036, 0.99893, 0.0007 ],\n",
              "       [0.     , 0.00591, 0.99408],\n",
              "       [0.99961, 0.00004, 0.00035],\n",
              "       [0.00001, 0.00046, 0.99953],\n",
              "       [0.99775, 0.00073, 0.00152],\n",
              "       [0.00047, 0.88453, 0.115  ],\n",
              "       [0.     , 0.00229, 0.99771],\n",
              "       [0.00001, 0.99676, 0.00322],\n",
              "       [0.99986, 0.00001, 0.00014],\n",
              "       [0.99947, 0.00008, 0.00046],\n",
              "       [0.0001 , 0.99595, 0.00395],\n",
              "       [0.00006, 0.98202, 0.01792],\n",
              "       [0.99869, 0.00028, 0.00104],\n",
              "       [0.00002, 0.9994 , 0.00058],\n",
              "       [0.99957, 0.00005, 0.00038],\n",
              "       [0.99813, 0.00053, 0.00134],\n",
              "       [0.99821, 0.00049, 0.0013 ],\n",
              "       [0.     , 0.00076, 0.99924],\n",
              "       [0.99886, 0.00024, 0.0009 ],\n",
              "       [0.     , 0.03725, 0.96275],\n",
              "       [0.00005, 0.01327, 0.98668],\n",
              "       [0.9993 , 0.00011, 0.00059],\n",
              "       [0.00003, 0.99601, 0.00396],\n",
              "       [0.00001, 0.99598, 0.00401],\n",
              "       [0.00004, 0.03786, 0.96211],\n",
              "       [0.9996 , 0.00004, 0.00036],\n",
              "       [0.00005, 0.99764, 0.00231],\n",
              "       [0.99951, 0.00007, 0.00042],\n",
              "       [0.00004, 0.65126, 0.3487 ],\n",
              "       [0.00007, 0.9939 , 0.00603],\n",
              "       [0.00015, 0.99928, 0.00057],\n",
              "       [0.     , 0.00006, 0.99994],\n",
              "       [0.00014, 0.99913, 0.00073],\n",
              "       [0.99861, 0.00035, 0.00105],\n",
              "       [0.00028, 0.99682, 0.00291],\n",
              "       [0.     , 0.00007, 0.99993],\n",
              "       [0.99847, 0.00041, 0.00112],\n",
              "       [0.00001, 0.00208, 0.99791],\n",
              "       [0.     , 0.0004 , 0.9996 ],\n",
              "       [0.00001, 0.01399, 0.98599]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_j30okDeHJdh",
        "outputId": "4d15491c-f038-4598-909e-05108e722c79"
      },
      "source": [
        "np.argmax(Model_iris.predict(X_test) , axis = 1)\n",
        "# argmax: 제일 큰 값의 index를 뽑아줌 (원핫인코딩 중 probability가 제일 높은 값의 인덱스를 구해줌\n",
        "# 많이 쓰인다"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_hCGHurHR3r"
      },
      "source": [
        "- One-Hot Encoding to Array\n",
        "  - OHE 상태로는 Confusion Matrix를 그릴 수 없다\n",
        "  - np.argmax(): 다차원 배열의 차원에 따라 가장 큰 값의 인덱스를 반환\n",
        "  - axis = 1 : 열 기준"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-9i5zeIHPPd",
        "outputId": "c1a484bb-821c-46b8-a561-ac7ee1cdba75"
      },
      "source": [
        "y = np.argmax(y_test, axis = 1)\n",
        "\n",
        "y"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yqf0tyEtHife"
      },
      "source": [
        "- Confusion Matrix & Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3V4kasTHfMj",
        "outputId": "6b51b819-6279-408f-c69f-36921696c8d0"
      },
      "source": [
        "confusion_matrix(y, y_hat)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17,  0,  0],\n",
              "       [ 0, 14,  0],\n",
              "       [ 0,  1, 13]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxTZqLFmHtTn",
        "outputId": "8802a876-03cc-4515-b4b7-9732160dada8"
      },
      "source": [
        "print(classification_report(y, y_hat,\n",
        "                            target_names = ['setosa' ,\n",
        "                                            'virginica' ,\n",
        "                                            'versicolor']))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        17\n",
            "   virginica       0.93      1.00      0.97        14\n",
            "  versicolor       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdkNka5rH2iY"
      },
      "source": [
        "## 3. Model Save & Load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgTjCC9xH4ve"
      },
      "source": [
        "### 1) File System\n",
        "- Save to Colab File System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT9zfgrEHzXf",
        "outputId": "3397b53f-6d00-4968-818a-680ddcaf1522"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "-rw-r--r-- 1 root root 7979 Mar 18 02:36 model.png\n",
            "drwxr-xr-x 1 root root 4096 Mar  5 14:37 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge9QsiD_H9e_",
        "outputId": "a62ca5a2-5ef0-4433-e990-d63c95ea8af5"
      },
      "source": [
        "Model_iris.save('Model_iris.h5')\n",
        "# colab에 저장된\n",
        "\n",
        "!ls -l"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 48\n",
            "-rw-r--r-- 1 root root 34592 Mar 18 02:36 Model_iris.h5\n",
            "-rw-r--r-- 1 root root  7979 Mar 18 02:36 model.png\n",
            "drwxr-xr-x 1 root root  4096 Mar  5 14:37 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8T1DEVQID5I"
      },
      "source": [
        "- Download Colab File System to Local File System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NMoIn4vUIC4w",
        "outputId": "e83a422a-1190-4bcf-822d-0b80f07143f7"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('Model_iris.h5')\n",
        "# local에 다운로드 됨 (마우스 클릭으로 다운로드 받아도 됨)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a521e8e4-1e84-43d6-9a11-ec62083f3327\", \"Model_iris.h5\", 34592)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIGz84pQIOCs"
      },
      "source": [
        "- Load from Colab File System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1IfpC88IMSl"
      },
      "source": [
        "Model_local = load_model('Model_iris.h5')\n",
        "# 243개의 파라미터 값을 획득"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5rUU3phIaRj",
        "outputId": "4bc4be38-c6fd-4ff1-cfea-3f1339af19f7"
      },
      "source": [
        "Model_local.predict_classes(X_test)\n",
        "# 분류작업을 해낸다"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1Jmoku6IefY"
      },
      "source": [
        "### 2) Google Drive\n",
        "- Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPLUFFsOIdgY",
        "outputId": "95df1b4b-ea67-4e78-db6e-9c89378dd88f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI7xyR-4Ipre"
      },
      "source": [
        "- Check Mounted_Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-IKL1HpIlfp",
        "outputId": "03a828a7-ee9e-4035-a516-f8223d1cd7be"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Colab Notebooks/datasets'"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1741130\n",
            "-rw------- 1 root root      20066 Mar  4 04:45 cat.1700.jpg\n",
            "-rw------- 1 root root   68787205 Mar  9 04:06 creditCardFraud.zip\n",
            "-rw------- 1 root root   90618980 Mar  4 04:51 dogs_and_cats_small.zip\n",
            "drwx------ 2 root root       4096 Mar  9 04:27 image\n",
            "-rw------- 1 root root    8204887 Mar  4 04:45 Images_500.zip\n",
            "-rw------- 1 root root    4240457 Mar 15 04:25 Kaggle_Customer_Satisfaction.zip\n",
            "-rw------- 1 root root   12929865 Mar  4 04:42 Logo_Data.zip\n",
            "-rw------- 1 root root   18272469 Mar  4 04:50 MNIST.csv\n",
            "-rw------- 1 root root   23715344 Mar  7 07:08 Online_Retail.xlsx\n",
            "-rw------- 1 root root        741 Mar  4 04:44 PII.csv\n",
            "-rw------- 1 root root 1141460846 Mar  4 04:50 waferImages.zip\n",
            "-rw------- 1 root root  414658234 Mar  4 04:49 yolo_weight.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCQC0Sn-I_MP"
      },
      "source": [
        "- Save to Mounted Google Drive Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDzhShBmIvTx"
      },
      "source": [
        "# 로컬에 저장해두면 손상될 수 있으니 google drive에 저장해두는 것\n",
        "Model_iris.save('/content/drive/My Drive/Colab Notebooks/models/001_Model_iris.h5')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwi46JxKJJWQ",
        "outputId": "22b95d70-18dd-43a9-d833-e1f3b086937f"
      },
      "source": [
        "!ls -l '/content/drive/My Drive/Colab Notebooks/models'"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 34\n",
            "-rw------- 1 root root 34592 Mar 18 02:42 001_Model_iris.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIffFAOGJW5o"
      },
      "source": [
        "- Load from Mounted Google Drive Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNP3cVB-JNxj"
      },
      "source": [
        "# 구글 드라이브에서 모델을 load\n",
        "Model_google = load_model('/content/drive/My Drive/Colab Notebooks/models/001_Model_iris.h5')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRTZFQ4AJkm6",
        "outputId": "fe983482-c240-489e-ecfd-aa14e8372f4d"
      },
      "source": [
        "Model_google.predict_classes(X_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
              "       2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 1, 0, 1, 2, 0, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eggCZDrVOn7x"
      },
      "source": [
        "- input과 output의 숫자만 맞춰주면, 남이 만든 모델도 가져와서 사용할 수 있다(transferred learning)"
      ]
    }
  ]
}